{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_Exercise_2_.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qYJcxpwEyxC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgYV9F8IE2L_",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 2 - Image Classification with CNNs\n",
        "![CIFAR10](https://miro.medium.com/max/964/1*syyml8q8s1Yt-iEea5m1Ag.png)\n",
        "\n",
        "[CIFAR 10](https://www.cs.toronto.edu/~kriz/cifar.html) is a small toy data set for image classifaction. \n",
        "\n",
        "* It has 60k images from ten diffenrent classes (like car, airplane, horse,..)\n",
        "* The RGB images are of size 32x32 pixels  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiDFXXcUEy-G",
        "colab_type": "code",
        "outputId": "0801a91b-1bcd-4cad-f5c5-03e9e23aaf7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "#import needed libs\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "#some vars to controll the training -> use them in your code\n",
        "batch_size = 32\n",
        "num_classes = 10 #fixed!\n",
        "epochs = 10\n",
        "\n",
        "# Get the data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 7s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmocaCkIGOIR",
        "colab_type": "text"
      },
      "source": [
        "## Task:\n",
        "* build and train the ***AlexNet*** CNN architecture from the lecture\n",
        "* use 'relu' functions for the non-linear activation\n",
        "* optimize the learning hyper-paramters to get the best  test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p5AD8mJEzmL",
        "colab_type": "code",
        "outputId": "d3741201-478c-40c2-c2ab-3489c4e83148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# 1. Conv\n",
        "model.add(Conv2D(filters=32, input_shape=(32,32,3), kernel_size=(3,3),padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# 2. Conv\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3),padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "# 2. MaxPool\n",
        "model.add(MaxPooling2D(pool_size=(2,2),padding='valid'))\n",
        "\n",
        "# 3. Conv\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3),strides=(1,1),padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "# 4. Conv\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3),strides=(1,1),padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "# 4. MaxPool\n",
        "model.add(MaxPooling2D(pool_size=(2,2),padding='valid'))\n",
        "\n",
        "# 6. Dense\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=512))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 15, 15, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1606144   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,676,842\n",
            "Trainable params: 1,676,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8Asq7GicMD8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "beee0e8b-fed2-4ff6-cf3b-9c5ea563c5da"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=batch_size, validation_data=(x_test,y_test), epochs=epochs,shuffle=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 255s 5ms/step - loss: 1.3050 - accuracy: 0.5369 - val_loss: 1.1157 - val_accuracy: 0.6135\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.9815 - accuracy: 0.6569 - val_loss: 0.9617 - val_accuracy: 0.6738\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.8121 - accuracy: 0.7154 - val_loss: 0.9097 - val_accuracy: 0.6934\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.6677 - accuracy: 0.7683 - val_loss: 0.9777 - val_accuracy: 0.6842\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.5456 - accuracy: 0.8115 - val_loss: 1.0198 - val_accuracy: 0.6907\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.4149 - accuracy: 0.8564 - val_loss: 1.1097 - val_accuracy: 0.7046\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.3351 - accuracy: 0.8861 - val_loss: 1.2771 - val_accuracy: 0.6928\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.2898 - accuracy: 0.9049 - val_loss: 1.3851 - val_accuracy: 0.6884\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 253s 5ms/step - loss: 0.2401 - accuracy: 0.9220 - val_loss: 1.7081 - val_accuracy: 0.6755\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 253s 5ms/step - loss: 0.2286 - accuracy: 0.9273 - val_loss: 1.5581 - val_accuracy: 0.6819\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fd71e577f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evT4ZeOBe9vP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "b3ae9be1-1d00-4691-c58d-f02a47add75b"
      },
      "source": [
        "print('\\n# Evaluate on test data')\n",
        "results = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "10000/10000 [==============================] - 12s 1ms/step\n",
            "test loss, test acc: [1.5580748621940612, 0.6819000244140625]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}